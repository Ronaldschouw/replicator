---
version: '2'
services:
  zookeeper-dc1:
    image: ${REPOSITORY}/cp-zookeeper:${CONFLUENT_DOCKER_TAG}
    hostname: zookeeper-dc1
    container_name: zookeeper-dc1
    ports:
      - "2181:2181"
      - "9997:9997"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data_dc1:/var/lib/zookeeper/data
      - zookeeper_log_dc1:/var/lib/zookeeper/log
      - ./etc/zookeeper.properties:/etc/kafka/zookeeper.properties

  zookeeper-dc2:
    image: ${REPOSITORY}/cp-zookeeper:${CONFLUENT_DOCKER_TAG}
    hostname: zookeeper-dc2
    container_name: zookeeper-dc2
    ports:
      - "2182:2182"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data_dc2:/var/lib/zookeeper/data
      - zookeeper_log_dc2:/var/lib/zookeeper/log

  broker-dc1:
    image: ${REPOSITORY}/cp-kafka:${CONFLUENT_DOCKER_TAG}
    hostname: broker-dc1
    container_name: broker-dc1
    depends_on:
      - zookeeper-dc1
    ports:
      - "9091:9091"
      - "9093:9093"
      - "9991:9991"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_JMX_PORT: 9991
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-dc1:2181'
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schema-registry-dc1:8081"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,SSL:SSL,SSL_HOST:SSL
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-dc1:29091,PLAINTEXT_HOST://localhost:9091,SSL://broker-dc1:29093,SSL_HOST://localhost:9093
      KAFKA_SSL_KEYSTORE_FILENAME: broker-dc1.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: cert_creds
      KAFKA_SSL_KEY_CREDENTIALS: cert_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: broker-dc1.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: cert_creds
      KAFKA_SSL_CLIENT_AUTH: 'required'
      KAFKA_SECURITY_PROTOCOL: SSL
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SSL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    volumes:
      - kafka_data_dc1:/var/lib/kafka/data
      - ./secrets:/etc/kafka/secrets

  broker-dc2:
    image: ${REPOSITORY}/cp-kafka:${CONFLUENT_DOCKER_TAG}
    hostname: broker-dc2
    container_name: broker-dc2
    depends_on:
      - zookeeper-dc2
    ports:
      - "9092:9092"
      - "9094:9094"
      - "9992:9992"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_JMX_PORT: 9992
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-dc2:2182'
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schema-registry-dc2:8082"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-dc2:29092,PLAINTEXT_HOST://localhost:9092

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,SSL:SSL,SSL_HOST:SSL
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-dc2:29092,PLAINTEXT_HOST://localhost:9092,SSL://broker-dc2:29094,SSL_HOST://localhost:9094
      KAFKA_SSL_KEYSTORE_FILENAME: broker-dc2.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: cert_creds
      KAFKA_SSL_KEY_CREDENTIALS: cert_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: broker-dc2.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: cert_creds
      KAFKA_SSL_CLIENT_AUTH: 'required'
      KAFKA_SECURITY_PROTOCOL: SSL
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SSL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    volumes:
      - kafka_data_dc2:/var/lib/kafka/data
      - ./secrets:/etc/kafka/secrets

  schema-registry-dc1:
    image: ${REPOSITORY}/cp-schema-registry:${CONFLUENT_DOCKER_TAG}
    hostname: schema-registry-dc1
    container_name: schema-registry-dc1
    restart: always
    depends_on:
      - broker-dc1
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-dc1
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker-dc1:29091'
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: ERROR

  schema-registry-dc2:
    image: ${REPOSITORY}/cp-schema-registry:${CONFLUENT_DOCKER_TAG}
    hostname: schema-registry-dc2
    container_name: schema-registry-dc2
    restart: always
    depends_on:
      - broker-dc1
      - schema-registry-dc1
    ports:
      - "8082:8082"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-dc2
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker-dc1:29091'
      SCHEMA_REGISTRY_LEADER_ELIGIBILITY: "false"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8082"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: ERROR

  connect-dc2:
    image: ${REPOSITORY}/cp-enterprise-replicator:${CONFLUENT_DOCKER_TAG}
    hostname: connect-dc2
    container_name: connect-dc2
    depends_on:
      - broker-dc1
      - schema-registry-dc1
      - broker-dc2
      - schema-registry-dc2
    ports:
      - "8382:8382"
      - "9892:9892"
    command: "bash -c 'cp /usr/share/java/kafka-connect-replicator/replicator-rest-extension-*.jar /etc/kafka-connect/jars/; /etc/confluent/docker/run'"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-dc2:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-dc2
      CONNECT_LISTENERS: http://connect-dc2:8382
      CONNECT_GROUP_ID: "connect-dc2"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer-dc2"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs-dc2
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets-dc2
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: connect-status-dc2
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/java
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker-dc2:29092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker-dc2:29092
      CONNECT_REST_EXTENSION_CLASSES: io.confluent.connect.replicator.monitoring.ReplicatorMonitoringExtension
      KAFKA_JMX_PORT: 9892
      KAFKA_JMX_HOSTNAME: connect-dc2
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false "

  datagen-dc1-topic1:
    image: ${REPOSITORY}/ksqldb-examples:${CONFLUENT_DOCKER_TAG}
    hostname: datagen-dc1-topic1
    container_name: datagen-dc1-topic1
    depends_on:
      - broker-dc1
      - schema-registry-dc1
    volumes:
      - $PWD/schema-dc1.avro:/tmp/schema-dc1.avro
      - $PWD/datagen-properties/datagen-dc1-topic1.properties:/tmp/datagen.properties
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker-dc1:29091 1 90 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       sleep 50 && \
                       cub sr-ready schema-registry-dc1 8081 90 && \
                       sleep 10 && \
                       /usr/bin/ksql-datagen schema=/tmp/schema-dc1.avro key=userid format=avro topic=topic1 msgRate=1 schemaRegistryUrl=http://schema-registry-dc1:8081 bootstrap-server=broker-dc1:29091 propertiesFile=/tmp/datagen.properties'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-silent.properties"
      STREAMS_BOOTSTRAP_SERVERS: broker-dc1:29091
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry-dc1
      STREAMS_SCHEMA_REGISTRY_PORT: 8081

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8089:8080
    depends_on:
      - broker-dc1
      - broker-dc2
      - zookeeper-dc1
      - zookeeper-dc2
      - schema-registry-dc1
      - schema-registry-dc2
      - connect-dc2
    environment:
      KAFKA_CLUSTERS_0_NAME: OLD
      KAFKA_CLUSTERS_1_NAME: NEW
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker-dc1:29093
      KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: broker-dc2:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry-dc1:8081
      KAFKA_CLUSTERS_1_SCHEMAREGISTRY: http://schema-registry-dc2:8082
      KAFKA_CLUSTERS_1_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_1_KAFKACONNECT_0_ADDRESS: http://connect-dc2:8382
      DYNAMIC_CONFIG_ENABLED: 'true'
      SERVER_SERVLET_CONTEXT_PATH: /kafka-ui

      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SSL
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_KEYSTORE_LOCATION: /server-dc1.keystore.jks
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_KEYSTORE_PASSWORD: "datahub"
      KAFKA_CLUSTERS_0_SSL_TRUSTSTORELOCATION: /server-dc1.truststore.jks
      KAFKA_CLUSTERS_0_SSL_TRUSTSTOREPASSWORD: "datahub"
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: '' # DISABLE COMMON NAME VERIFICATION
    volumes:
      - ./secrets/broker-dc1.truststore.jks:/server-dc1.truststore.jks
      - ./secrets/broker-dc1.keystore.jks:/server-dc1.keystore.jks



  grafana:
    image: "grafana/grafana:${GRAFANA_VERSION}"
    ports:
     - "3000:3000"
    environment:
      GF_PATHS_DATA : /var/lib/grafana
      GF_SECURITY_ADMIN_PASSWORD : kafka
    volumes:
     - ./grafana/provisioning:/etc/grafana/provisioning
     - ./grafana/dashboards:/var/lib/grafana/dashboards
    container_name: grafana
    depends_on:
     - prometheus

  prometheus:
    image: "prom/prometheus:${PROMETHEUS_VERSION}"
    ports:
     - "9090:9090"
    volumes:
     - ./etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: "--config.file=/etc/prometheus/prometheus.yml"
    container_name: prometheus

  jmx-kafka101:
    image: "sscaling/jmx-prometheus-exporter"
    ports:
     - "5556:5556"
    environment:
     CONFIG_YML : "/etc/jmx_exporter/config.yml"
     JVM_OPTS: ${PROMETHEUS_JMX_AGENT_JVM_OPTS}
    volumes:
     - ./etc/jmx_exporter/config_kafka101.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka101
    depends_on:
     - broker-dc1

  jmx-kafka102:
    image: "sscaling/jmx-prometheus-exporter"
    ports:
     - "5557:5556"
    environment:
     CONFIG_YML : "/etc/jmx_exporter/config.yml"
     JVM_OPTS: ${PROMETHEUS_JMX_AGENT_JVM_OPTS}

    volumes:
     - ./etc/jmx_exporter/config_kafka102.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka102
    depends_on:
     - broker-dc2

  dozzle:
    container_name: dozzle
    image: amir20/dozzle:v3.10.2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    expose:
      - 8080

  dozzle_nginx:
    image: ronaldschouw/nginx
    container_name: dozzle_nginx
    ports:
      - 9999:9999
    volumes:
      - ./app.conf:/etc/nginx/conf.d/default.conf:cached


volumes:
  zookeeper_data_dc1:
    driver: local
    name: zookeeper_data_dc_1
  zookeeper_log_dc1:
    driver: local
    name: zookeeper_log_dc_1
  kafka_data_dc1:
    driver: local
    name: kafka_data_dc1
  zookeeper_data_dc2:
    driver: local
    name: zookeeper_data_dc_2
  zookeeper_log_dc2:
    driver: local
    name: zookeeper_log_dc_2
  kafka_data_dc2:
    driver: local
    name: kafka_data_dc2
